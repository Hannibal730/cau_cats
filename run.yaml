# =============================================================================
# 1. 실행 및 데이터 관련 설정
# =============================================================================
run:
  mode: 'train' # 실행 모드. 'train': 모델 훈련, 'inference': 모델 추론 및 성능 평가
  # 데이터셋 경로 (절대 경로 사용 예시)
  train_img_dir: 'D:/Sewer-ML/SewerML/Train'
  valid_img_dir: 'D:/Sewer-ML/SewerML/Train' # 검증셋도 훈련셋 이미지를 사용
  test_img_dir: 'D:/Sewer-ML/SewerML/Test'
  train_csv: 'D:/Sewer-ML/SewerML_Train.csv'
  valid_csv: 'D:/Sewer-ML/SewerML_Val.csv'
  test_csv: 'D:/Sewer-ML/SewerML_Test.csv'
  model_path: 'best_model.pth' # 훈련 시 저장할 최고 성능 모델의 파일 이름 또는 추론 시 불러올 모델의 파일 이름.
  sampling_ratio: 0.1 # 각 데이터셋(train/valid/test)에서 사용할 데이터 비율. 1.0이면 전체 데이터 사용.
  random_seed: 42 # 데이터 샘플링 시 사용할 랜덤 시드. 재현성을 위해 고정합니다.

# =============================================================================
# 2. 훈련 하이퍼파라미터
# =============================================================================
training:
  epochs: 30                 
  batch_size: 16               # 훈련 및 평가 시 사용할 배치 크기. GPU 메모리에 따라 조절합니다.
  lr: 0.001                    # 옵티마이저(AdamW)의 학습률.

# =============================================================================
# 3. 모델 아키텍처 파라미터
# =============================================================================
model:
  # --- 이미지 및 인코더 설정 ---
  img_size: 480                # 모델에 입력하기 전 이미지의 리사이즈 크기 (정사각형).
  in_channels: 3               # 입력 이미지의 채널 수. 옵션: 1 (흑백), 3 (컬러).
  patch_size: 120              # 이미지를 나눌 정사각형 패치의 크기. `img_size`는 `patch_size`로 나누어 떨어져야 합니다.
  cnn_feature_extractor:
    # 이미지 패치에서 특징을 추출할 CNN 모델을 선택합니다.
    # 사용 가능한 옵션:
    # - 'resnet18_layer1': ResNet18의 layer1까지 사용
    # - 'resnet18_layer2': ResNet18의 layer2까지 사용
    # - 'mobilenet_v3_small_feat1': MobileNetV3-Small의 features[1]까지 사용
    # - 'mobilenet_v3_small_feat3': MobileNetV3-Small의 features[3]까지 사용
    # - 'efficientnet_b0_feat2': EfficientNet-B0의 features[2]까지 사용
    # - 'efficientnet_b0_feat3': EfficientNet-B0의 features[3]까지 사용
    name: 'efficientnet_b0_feat2'    

  # --- CATS 모델 설정 ---
  cats:
    featured_patch_channel: 32 # CNN 특징 추출기가 각 이미지 패치에서 추출하는 특징 벡터의 채널 수(길이).
    emb_dim: 24                # CATS 트랜스포머 모델 내부에서 사용하는 통일된 임베딩 차원(d_model).
    n_heads: 4                 # 멀티헤드 어텐션에서 사용할 헤드의 수. `emb_dim`은 `n_heads`로 나누어 떨어져야 합니다.
    d_layers: 2                # CATS 모델 내부의 트랜스포머 디코더 레이어 수.
    d_ff_ratio: 2              # 트랜스포머의 피드포워드 네트워크(FFN) 내부 차원을 결정하는 비율 (d_ff = emb_dim * d_ff_ratio).
    dropout: 0.1               # CATS 모델 내부에 적용될 드롭아웃 비율.
    channel_independence: True # 학습 가능한 쿼리(learnable_queries)의 채널별 독립성 여부. True이면 모든 채널이 쿼리 파라미터를 공유하고, False이면 채널별로 다른 쿼리를 학습합니다.
    padding_patch: 'end'       # CATS 모델이 내부적으로 1D 시퀀스를 패치로 나눌 때 사용할 패딩 전략.
    store_attn: False          # 추론 시 어텐션 맵을 저장할지 여부. True로 설정하면 시각화에 사용할 수 있습니다.
    classification: True       # 모델을 분류 문제용으로 설정. CATS 모델의 출력 구조에 영향을 줍니다.
    qam:                       # Query-Adaptive Masking 설정. 트랜스포머 레이어의 과적합을 방지하는 기법입니다.
      # start와 end를 0.0으로 설정하면 비활성화됩니다.
      start: 0.0
      end: 0.5