# run.py 최종 분석: 전체 실행 과정

`run.py`는 `run.yaml` 설정 파일을 기반으로 **CNN-트랜스포머 하이브리드 모델**의 훈련 및 추론 파이프라인 전체를 관장하는 실행 스크립트입니다.

## 1. 설정 및 환경 준비 (`if __name__ == '__main__':` 블록 초반)

-   **설정 파일 로드**: `python run.py --config run.yaml` 명령어로 스크립트가 실행되면, `argparse`가 `--config` 인자를 읽어 `run.yaml` 파일의 경로를 가져옵니다. `yaml.safe_load`로 파일 내용을 파싱하고, `SimpleNamespace`를 사용해 `config.run.mode`와 같이 객체 속성으로 쉽게 접근할 수 있는 설정 객체들(`run_cfg`, `train_cfg`, `model_cfg`, `cats_cfg`)을 생성합니다.
-   **로깅 시작 (`setup_logging`)**: `log/Sewer-ML/` 폴더에 타임스탬프가 찍힌 로그 파일(`log_20231028_103000.log`)을 생성하여, 이후의 모든 과정을 기록하기 시작합니다.
-   **장치 설정**: `torch.device`를 통해 사용 가능한 경우 GPU(CUDA)를, 그렇지 않으면 CPU를 연산 장치(`device`)로 설정합니다.

## 2. 데이터 준비 (`prepare_data`)

-   **데이터셋 객체 생성**: `CustomImageDataset` 클래스가 `run.yaml`에 명시된 CSV 파일 경로(`train_csv`, `valid_csv`, `test_csv`)를 읽어, 각 데이터셋의 모든 이미지 파일명과 레이블 정보를 메모리에 로드합니다.
-   **데이터 증강 정의**: 훈련 데이터에만 적용될 `train_transform` (회전, 확대/축소, 반전 등)과, 검증/테스트 데이터에 적용될 `valid_test_transform` (리사이즈 및 정규화)을 정의합니다.
-   **샘플링**: `run.yaml`의 `sampling_ratio`가 1.0 미만일 경우, `Subset` 클래스를 사용하여 전체 데이터셋 중 지정된 비율만큼의 인덱스만 무작위로 추출하여 더 작은 데이터셋을 구성합니다.
-   **DataLoader 생성**: 최종적으로 구성된 `Dataset` 객체들을 `DataLoader`로 감싸줍니다. `DataLoader`는 데이터를 `batch_size`에 맞춰 미니배치 단위로 묶고, 훈련 시 데이터 순서를 섞어주는 등 훈련 파이프라인에 데이터를 효율적으로 공급합니다.

## 3. 모델 구성 (`if __name__ == '__main__':` 블록 중반)

`HybridModel`은 세 개의 핵심 모듈(`encoder`, `decoder`, `classifier`)을 조립하여 완성됩니다. 각 모듈이 어떻게 구성되고 데이터가 어떻게 흘러가는지 텐서 차원과 함께 자세히 살펴보겠습니다. (`run.yaml` 설정값 기준: `batch_size=16`, `img_size=480`, `patch_size=120`, `featured_patch_dim=32`, `emb_dim=24`, `num_labels=2`)

### 3.1. 인코더: `PatchConvEncoder`

-   **역할**: 2D 이미지를 입력받아, 이를 여러 개의 패치로 나눈 뒤 각 패치에서 특징을 추출하여 최종적으로 트랜스포머가 입력으로 받을 수 있는 1D 벡터 시퀀스로 변환하는 인코더입니다.
-   **`forward` 함수 상세 흐름**:
    1.  **입력**: `[B, C, H, W]` 형태의 이미지 배치.
        -   `[16, 3, 480, 480]`
    2.  **패치화 및 재배열**: `unfold`와 `reshape`을 통해 이미지를 패치로 나누고, 모든 패치를 하나의 거대한 배치로 만듭니다.
        -   `num_encoder_patches` = (480 / 120) \* (480 / 120) = 16
        -   텐서 모양: `[16 * 16, 3, 120, 120]` -> `[256, 3, 120, 120]`
    3.  **특징 추출 (`shared_conv`)**: `CnnFeatureExtractor`가 각 패치에서 특징을 추출하고, `AdaptiveAvgPool2d`와 `Flatten`을 거쳐 각 패치당 하나의 특징 벡터를 생성합니다.
        -   텐서 모양: `[256, 32]`
    4.  **정규화 (`norm`)**: `LayerNorm`이 각 패치의 특징 벡터를 정규화합니다.
        -   텐서 모양: `[256, 32]`
    5.  **최종 시퀀스 생성 (`view`)**: 패치들을 다시 원래 이미지 단위로 그룹화합니다.
        -   **Encoder 최종 출력**: `[16, 16, 32]` (`[B, num_encoder_patches, featured_patch_dim]`)

### 3.2. 디코더: `CatsDecoder`

-   **역할**: 인코더가 생성한 패치 시퀀스를 입력받아, 크로스-어텐션(Cross-Attention) 메커니즘을 통해 분류에 핵심적인 정보만을 추출하고 압축하는 디코더 역할을 수행합니다.
-   **`forward` 함수 상세 흐름**:
    1.  **입력**: 인코더의 출력인 `[B, num_encoder_patches, featured_patch_dim]`
        -   `[16, 16, 32]`
    2.  **Key, Value 생성 (`Learnable_Query_Embedding.forward`)**:
        -   입력 시퀀스가 `W_feat2emb` 레이어를 통과하여 모델 내부 차원(`emb_dim`)으로 변환되고, 위치 정보(`PE`)가 더해집니다. 이것이 어텐션의 키(Key)와 값(Value) 역할을 하는 `seq_encoder_patches`가 됩니다.
        -   텐서 모양: `[16, 16, 24]` (`[B, num_encoder_patches, emb_dim]`)
    3.  **Query 생성 (`Learnable_Query_Embedding.forward`)**:
        -   `num_decoder_patches` = (2 + 32 - 1) // 32 = 1
        -   `learnable_queries` 파라미터가 `W_feat2emb`를 통과하여 `emb_dim` 차원으로 변환된 후, 배치 크기만큼 복제됩니다. 이것이 어텐션의 쿼리(Query) 역할을 하는 `seq_decoder_patches`가 됩니다.
        -   텐서 모양: `[16, 1, 24]` (`[B, num_decoder_patches, emb_dim]`)
    4.  **크로스-어텐션 (`Decoder`)**: `Decoder` 모듈 내부에서, `seq_decoder_patches`(Query)가 `seq_encoder_patches`(Key, Value)에게 질문을 던져 중요한 특징을 추출하고 조합합니다.
        -   어텐션 후 텐서 모양: `[16, 1, 24]` (`[B, num_decoder_patches, emb_dim]`)
    5.  **최종 출력 (`Decoder2Classifier`)**: `Decoder2Classifier` 헤드가 디코더의 출력을 받아 선형 변환 및 평탄화(flatten)를 수행합니다.
        -   `linear` 통과 후: `[16, 1, 32]` (`[B, num_decoder_patches, featured_patch_dim]`)
        -   `flatten` 통과 후: `[16, 32]` (`[B, num_decoder_patches * featured_patch_dim]`)
        -   **Decoder 최종 출력**: `[16, 32]`

### 3.3. `Classifier`

-   **역할**: `CatsDecoder`로부터 전달받은 압축된 특징 벡터를 가지고 최종적으로 이미지가 어떤 클래스에 속하는지 예측합니다.
-   **`forward` 함수 상세 흐름**:
    1.  **입력**: `CatsDecoder`의 출력인 `[B, num_decoder_patches * featured_patch_dim]`
        -   `[16, 32]`
    2.  **드롭아웃**: 훈련 시 과적합 방지를 위해 드롭아웃을 적용합니다.
    3.  **최종 예측 (`projection`)**: 선형 레이어가 특징 벡터를 최종 클래스 수(`num_labels`)로 매핑합니다.
        -   **Classifier 최종 출력**: `[16, 2]` (`[B, num_labels]`)

## 4. 훈련 및 평가 실행 (`if __name__ == '__main__':` 블록 후반)

-   **모델 파라미터 로깅 (`log_model_parameters`)**: 구성된 `HybridModel`의 각 부분(Encoder, Decoder, Classifier)에 학습 가능한 파라미터가 몇 개인지 계산하여 로그에 출력합니다.
-   **실행 모드 분기**:
    -   **`mode: 'train'`**:
        1.  `train` 함수가 호출됩니다. 이 함수는 `epochs` 수만큼 훈련을 반복하며, 각 에포크가 끝날 때마다 `evaluate` 함수를 호출하여 검증 데이터셋(`valid_loader`)에 대한 F1 점수를 측정합니다. 최고 F1 점수를 기록한 모델의 가중치는 `checkpoints/Sewer-ML/best_model.pth`에 저장됩니다.
        2.  모든 훈련이 끝나면, `inference` 함수가 호출되어 저장된 최고 성능 모델을 불러온 뒤, 한 번도 보지 않은 테스트 데이터셋(`test_loader`)으로 최종 성능을 평가하고 로그에 기록합니다.
    -   **`mode: 'inference'`**:
        -   `train` 과정을 건너뛰고, `inference` 함수만 호출하여 저장된 모델로 즉시 테스트 데이터셋에 대한 성능을 평가합니다.

이처럼 `run.py`는 설정 파일 기반의 유연성, 체계적인 로깅, 모듈화된 모델 구조, 표준화된 훈련/평가 파이프라인을 갖춘 매우 잘 설계된 딥러닝 실행 스크립트입니다.
